# ğŸ“¡ Telecom Big-Data Pipeline â€“ Mediation â†’ Rating â†’ Billing â†’ Reporting

> **Goal:** Convert raw network usages (CDR/EDR) into reliable revenue and business KPIs  
> **Stack:** Kafka | Apache Spark (Structured Streaming + Batch) | PostgreSQL | Parquet | Power BI  

---

## ğŸŒ End-to-End Architecture

```mermaid
flowchart LR
  A[Kafka<br>CDR topic] --> B(Spark Streaming<br>Mediation & Clean)
  B -->|Parquet /record_type| C[cleaned_cdrs]
  C --> D(Spark Batch<br>Rating Engine)
  subgraph PostgreSQL
    E[customers]
  end
  subgraph ressources
    F[rate_plans]
    G[product_catlog]
  end
  D --JDBC--> E
  D --CSV--> F
  D --CSV--> G
  D -->|Parquet| H[rated_cdrs/]
  H --> I(Spark Batch<br>Billing Engine)
  I -->|Parquet| J[facturation_complete/]
  J --> K[Power BI Dashboard]
```
## ğŸ“‚ Project Layout
```
project-root/
â”œâ”€â”€ conf/                                         # External dependencies (JARs, configs)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ synthetic_data_generation.py              # Generates synthetic CDRs
â”‚   â”œâ”€â”€ streaming_mediation.py                    # Spark Structured Streaming mediation
â”‚   â”œâ”€â”€ rating_engine.ipynb                       # Spark batch job â€“ Rating Engine
â”‚   â”œâ”€â”€ billing_engine.ipynb                      # Spark batch job â€“ Billing Engine
â”‚   â”œâ”€â”€ kafka_streaming.py                        # Kafka producer
â”‚   â”œâ”€â”€ initialise_pg.py                          # PostgreSQL schema & seed initialisation
â”‚   â””â”€â”€ reporting.ipynb                           # Spark job â†’ CSV export for BI
â”œâ”€â”€ resources/
â”‚   â”œâ”€â”€ product_catalog.csv
â”‚   â””â”€â”€ rate_plans.csv
â”œâ”€â”€ cleaned_cdrs/                                 # Parquet output from mediation stage
â”œâ”€â”€ rated_cdrs/                                   # Parquet output from rating stage
â”œâ”€â”€ billing/                                      # Parquet output from billing stage
â””â”€â”€ report/                                       # Final CSVs ready for Power BI
```
## âš™ï¸ Prerequisites
| Tool                 | Version tested               |
| -------------------- | ---------------------------- |
| **Python**           | 3.9                         |
| **Spark**            | 3.5.x (âš  driver JDBC ajoutÃ©) |
| **Kafka**            | 3.x                          |
| **PostgreSQL**       | â‰¥ 12                         |

## Installation

1. Clone the repository and navigate to the project folder:
    ```bash
    git clonehttps://github.com/Houssam-Ibnchakroune/Telecom-Data-Pipeline.git
    cd Telecom-Data-Pipeline
    ```


## Configuration

- **Kafka**: Ensure Kafka is installed and running locally.
- **PySpark**:  Modify `bootstrap.servers` in the spark configuration if necessary.
- **PostgreSQL**: Update PostgreSQL connection settings (host, user, password, database) in the code to match your local PostgreSQL setup.

## Usage

1. **Start zookeper**:
    ```bash
    # In one terminal
    .\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties
    ```
    
2. **Start Kafka-server**:
   ```bash
    # In one terminal
    .\bin\windows\kafka-server-start.bat .\config\server.properties
    ```
   
3. **run the CDR producer**:
   ```bash
    # In one terminal (Python 3.9+ active)
    python kafka_streaming.py
   
4. **run the job Spark Streaming (mÃ©diation)**:
   ```bash
    # In one terminal (or in IDE like vs code)
    python Streaming-Based_Mediation.py
   
5. **run the notebooks/ scripts batch de rating,billing and reporting **:
   ```bash
    # In one terminal (or in IDE like vs code)
    python run_pipline.py
6. **Visualize in Power BI**:
    - Start Power BI and read the CSVs files in report/ directory as the data source.
    - Create dashboards for  visualization.


## Example Dashboard in Grafana

In Power BI, create panels to visualize metrics like **Daily Revenue**, **Revenue by Plan and region**, and **Top 10 Data Consumers**.



## Contributeurs

- [Ibnchakroune Houssam](https://github.com/houssam-ibnchakroune) â€” Lead developer  
- [Kamal Salma](https://github.com/SALMAKAMAL21) â€” Lead developer
  
---

**Note :** This project is for educational and demonstration purposes. Results may vary depending on the quality and quantity of generated data.
